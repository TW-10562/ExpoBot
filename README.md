Digital Twin
Enterprise RAG‚ÄëBased Knowledge Assistant
üìå Overview
Digital Twin is a modular Retrieval‚ÄëAugmented Generation (RAG) platform designed for enterprise internal knowledge use cases such as HR policy Q&A and document intelligence.

The system follows a role‚Äëbased architecture, where:

Admins manage documents, analytics, and users

End users only consume information

It is built with clear separation of concerns across UI, API orchestration, and RAG intelligence layers.

üèóÔ∏è High‚ÄëLevel Architecture
React UI
   ‚Üì
Node.js API (Orchestrator & Access Control)
   ‚Üì
Python RAG Engine
   ‚Üì
RAG Knowledge Database
Infrastructure Services

MySQL ‚Üí metadata, users, document records

Redis ‚Üí caching & session support

Docker ‚Üí service orchestration

üë• User Roles & Permissions
üîë Admin
Upload documents to RAG database

View system analytics

Monitor user activity

Access all user query history

Manage RAG modes

üë§ User
Ask questions via chat UI

View own query history

Read AI‚Äëgenerated answers

No access to uploads or analytics

üß© Core Modules
1Ô∏è‚É£ UI Layer (ui/)
Technology: React + pnpm

Login / SSO

Chat interface

Answer display

User history view

Role‚Äëbased UI rendering (Admin / User)

‚ö†Ô∏è UI never communicates directly with RAG.

2Ô∏è‚É£ API Layer (api/)
Technology: Node.js + TypeScript

Acts as the central control layer.

Responsibilities:

Authentication & role enforcement

Admin‚Äëonly file upload APIs

Routing requests to correct RAG mode

Collecting analytics & usage metrics

Returning formatted responses to UI

3Ô∏è‚É£ RAG Engine (rag/)
Technology: Python (Conda environment)

Responsibilities:

Document ingestion (Admin only)

Embedding & retrieval logic

Mode‚Äëspecific RAG processing

Returning retrieved answers to API

All uploaded files are stored in the RAG database and used for retrieval.

4Ô∏è‚É£ Infrastructure Layer
Dockerized Services

MySQL

Chroma DB

Redis

These services must be running before API & RAG.

‚ñ∂Ô∏è How to Run the Project
Prerequisites
- Docker 24+ and Docker Compose v2
- Node.js 18+ (recommended 20+), pnpm 9+
- Python 3.10+ (virtualenv or conda)
- Optional: NVIDIA GPU + CUDA 12.x for faster RAG inference

‚úÖ Step 1: Start Infrastructure
docker compose up -d
Verify: docker compose ps

Services started by Compose
- MySQL 8.0 ‚Üí 3306 (seeded via api/src/mysql/scripts/*.sql)
- Redis ‚Üí 6379 
- Solr ‚Üí 8983 (core: mycore)

‚úÖ Step 2: Configure the app
- Global config: config/default.yml (also mirrored at api/config/default.yml)
   - Backend API: host/port, JWT secrets
   - RAG backend: host/port/url
   - Vector store and uploads paths
   - Models (Ollama/HuggingFace)
   - Azure AD SSO: TENANT_ID, CLIENT_ID, CLIENT_SECRET, REDIRECT_URI
- Placeholders like <PROJECT_ROOT_DIR> are auto‚Äëexpanded at runtime.

‚úÖ Step 3: Start the API (Node.js)
cd api
pnpm install
pnpm dev
Runs Koa API on 9090 with role‚Äëbased access and file uploads.
Optional:
- Background worker: pnpm worker
- Bull Board (job monitor): http://localhost:9999

‚úÖ Step 4: Start the RAG Engine (Python/FastAPI)
cd rag
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
python main.py
Starts FastAPI on 8000; first run downloads models to rag/data/model.
Notes:
- GPU is auto‚Äëdetected in dev-init.sh; CPU fallback is supported.
- Retrieval config in config/default.yml ‚Üí RAG.Retrieval

‚úÖ Step 5: Start the UI (React/Vite)
cd ui-2
pnpm install
pnpm dev
Launches on http://localhost:7001 (proxy /dev-api ‚Üí http://localhost:9090)

üîê Login & SSO
Standard UI
http://localhost:7001
SSO Login
http://localhost:7001/login?sso=true
Authentication and role validation are handled by the API layer.

üì§ Document Upload (Admin‚ÄëOnly)
Only Admin users can upload documents

Uploaded documents are:

Validated

Stored in the RAG database

Indexed for retrieval

Users can immediately query newly uploaded content

üìä Analytics & Monitoring (Admin‚ÄëOnly)
Admins can view:

Total queries per user

Document usage statistics

RAG mode usage

Query frequency & trends

Complete chat history of all users

üîÅ RAG Mode Configuration
RAG behavior is configured in:

config/default.yml
Example:

RAG:
  mode: hr_policy
‚ö†Ô∏è Changing modes requires re‚Äëuploading documents.

‚ûï Adding a New RAG Mode
Only two files are required.

API Side
api/src/ragclass/<mode_name>.ts
Must implement:

export interface RAGProcessor {
  upload(...)
  search(...)
}
RAG Side (Python)
rag/api/modeAPI/<mode_name>_api.py
Optional Solr access:

rag/utils/solr.py ‚Üí get_solr_doc_by_id()
üîÑ End‚Äëto‚ÄëEnd Workflow
Admin uploads documents ‚Üí stored in RAG DB

User submits a query via UI

API validates user & routes request

Python RAG engine retrieves relevant content

Answer returned to API

API sends formatted response to UI

Query & response logged for analytics

üéØ Key Design Principles
Role‚Äëbased access control

Modular microservice architecture

Admin‚Äëcontrolled knowledge ingestion

Scalable RAG mode extension

Enterprise‚Äëready auditability

üß† One‚ÄëLine Summary
Aviary Lite is an enterprise RAG platform where admins manage knowledge and analytics, while users securely access AI‚Äëgenerated answers through a React UI, orchestrated by a Node.js API and powered by Python‚Äëbased RAG engines.

‚Äî

Appendix: Complete Project Setup and Configuration

Project Ports
- UI (Vite dev server): 7001
- API (Koa): 9090
- RAG (FastAPI): 8000
- FAQ Cache (optional): 8001
- Bull Board (jobs UI): 9999
- MySQL: 3306
- Redis: 6379
- Solr: 8983

## Aviary Integration (api)

### New backend endpoints
- `GET /api/health` - lightweight health status
- `POST /api/chat/stream` - SSE token streaming (Ollama NDJSON pass-through)
- `POST /api/task` - enqueue async task
- `GET /api/task/:id` - async task status/result
- BullBoard remains at `http://localhost:9999`

### Environment overrides
The API still reads `config/default.yml`, plus these optional runtime overrides:
- `OLLAMA_BASE_URL` (single URL or comma-separated URLs)
- `OLLAMA_MODEL`

Example:
```bash
export OLLAMA_BASE_URL="http://localhost:11435,http://localhost:11436"
export OLLAMA_MODEL="gpt-oss:120b"
```

### RBAC behavior
- Permissions are resolved from `user_role -> role_menu -> sys_menu.perms` (comma-separated perms supported).
- Computed permissions are stored in Redis session at login and refreshed when `update_userInfo` is triggered.
- Admin wildcard `*|*` bypasses checks.
- Permission checks support exact (`R|role`) and typed (`R` + `type=role`) matching.
- File-level RBAC is enforced with `useFilePermission(...)` via `file_role` mapping (deny by default).

### RBAC verification script
```bash
cd api
pnpm install
pnpm verify:rbac
```

### Run commands
```bash
cd api
pnpm dev         # API server
pnpm worker      # Bull worker processors
```

Database Initialization (MySQL)
- Compose mounts api/src/mysql/scripts to /docker-entrypoint-initdb.d
- Creates core tables (user, group, roles, files, messages, support_tickets, notifications, etc.)
- Seeds default users and roles. Change passwords immediately in production.
- Data persists in data/volumes/data/mysql-data

Configuration Files
- Root: config/default.yml
- API: api/config/default.yml (kept in sync with root)
- Key sections:
   - Backend: host, port, jwtSecret, jwtRefreshSecret, tokenizer, context window
   - RAG.Backend: host, port, url
   - RAG.VectorStore: type, path (default rag/app/rag_db)
   - RAG.Uploads: rootDir, filesDir, uploadDirectory, maxFileSize
   - RAG.useFaqCache and FaqCacheSettings.cacheApiUrl (default http://localhost:8001)
   - Models: chat/summary/translate (Ollama), ragEmbeddingModel, ragRerankModel (HF)
   - AZURE_AD: TENANT_ID, CLIENT_ID, CLIENT_SECRET, REDIRECT_URI

Environment Variables
- API: UPLOAD_DIR (default uploads)
- Python: standard Hugging Face envs (e.g., HF_HOME) respected; models cached under rag/data/model by config

Optional Services
- FAQ Cache (faq_database)
   - cd faq_database && pip install -r requirements.txt && python main.py
   - Runs at 8001 with /query, /status, /health endpoints
   - Enable by setting RAG.useFaqCache: true and adjusting RAG.FaqCacheSettings
- Solr (text extraction and page indexing)
   - dev-init.sh adds schema fields and precreates core mycore
   - Used by splitByPage pipeline for PDF indexing and hybrid search

Background Jobs
- A Bull queue is included for async tasks
- Start worker with pnpm worker
- Monitor at http://localhost:9999

API Endpoints (high level)
- Auth/User: /user/login, /user/logout, /user/getInfo, /user/list, /user/create, /user/update
- Files: /api/files/upload, /api/files, /api/files/tags, /api/files/preview/:storage_key, /api/files/download/:storage_key
- RAG tasks: /api/gen-task, /api/gen-task-output/*, /api/gen-task/getChatTitle
- Insights: /api/live-queries, /api/chat-history, /api/recent-chats
- Admin: /api/admin/users, /api/admin/activity, /api/admin/stats

RAG Engine Endpoints
- POST /upload (single file to collection)
- POST /upload-pdf-pages/solr (batch pages by Solr doc IDs)
- POST /search and /search/hybrid
- PUT /update, DELETE /collection, DELETE /record
- POST /check_embedding_model

Add a New RAG Mode
- API: api/src/ragclass/<mode_name>.ts implements RAGProcessor with upload() and search()
- RAG: rag/api/modeAPI/<mode_name>_api.py provides complementary endpoints
- Register and route mode in existing controllers; update config/default.yml if needed

Troubleshooting
- Ports in use: change Frontend/Backend/RAG ports in config/default.yml
- CUDA not available: set RAG.Retrieval.throwErrorWhenCUDAUnavailable: false (CPU fallback)
- Model downloads slow: pre‚Äëset HF_HOME or cacheDir to a local mirror; ensure internet access
- MySQL init didn‚Äôt run: remove data/volumes/data/mysql-data and re‚Äëup Docker (will re‚Äëseed)
